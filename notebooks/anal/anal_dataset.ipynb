{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07963501-f9fc-4b3d-858d-9dc3f1a48028",
   "metadata": {},
   "source": [
    "## Dataset Preparation and Model Inference Using GeneRAIN\n",
    "\n",
    "This notebook is designed as a guide for preparing datasets suitable for the GeneRAIN models and conducting model inference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f96a0c9-53e2-4e22-b26e-a358c97e7bcf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "- **Setting Up**: Assign the JSON file containing parameters for the model you wish to use to the environment variable `PARAM_JSON_FILE`. Begin by importing all the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "181363db-67be-46c8-8a55-a75f5f7d69c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/561/zs2131/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run in training mode!\n",
      "param_json_file is /g/data/yr31/zs2131/tasks/2023/RNA_expr_net/DeepGeneNet/jsons/exp7_GPT_coding_lncRNA.param_config.json\n",
      "Parameter of TOTAL_NUMBER_OF_DATASETS not found in the input json file, use default value of 5!\n",
      "Parameter of DATASET_TO_GET_FOR_MIXED_DATASET not found in the input json file, use default value of None!\n",
      "Parameter of PERFORMER_NET_LAST_LAYER_REQUIRES_GRAD not found in the input json file, use default value of True!\n",
      "Parameter of FINETUNE_TO_RECONSTRUCT_EXPR_OF_ALL_GENES not found in the input json file, use default value of False!\n",
      "Parameter of USE_PRETRAIN_MODEL_FOR_FINETUNE not found in the input json file, use default value of True!\n",
      "Parameter of PRETRAIN_EXPERIMENT_FOR_FINETUNE not found in the input json file, use default value of exp9!\n",
      "Parameter of OUTPUT_ATTENTIONS not found in the input json file, use default value of False!\n",
      "Parameter of OUTPUT_HIDDEN_STATES not found in the input json file, use default value of False!\n",
      "Parameter of ONLY_USE_PERTURBED_GENE_TO_PREDICT not found in the input json file, use default value of False!\n",
      "Parameter of LEARN_ON_ZERO_EXPR_GENES not found in the input json file, use default value of False!\n",
      "Parameter of OUTPUT_PARAMETER_HIST_TO_TENSOBOARD_BY_BATCH not found in the input json file, use default value of False!\n",
      "Parameter of PERTURBED_GENE_ALWAYS_IN_INPUT_EXPR_IN_PERTURB_DATASET not found in the input json file, use default value of False!\n",
      "Parameter of USE_AND_KEEP_ZERO_EXPR_GENES not found in the input json file, use default value of True!\n",
      "Parameter of SHUFFLE_GENE_INDICES_IN_EVALUATION not found in the input json file, use default value of False!\n",
      "Parameter of SHUFFLE_EXPR_INDICES_IN_EVALUATION not found in the input json file, use default value of False!\n",
      "Parameter of METHOD_TO_COMBINE_INPUT_AND_ENCODING not found in the input json file, use default value of None!\n",
      "Parameter of PRETRAIN_MODEL_CHECKPOINT_PATH not found in the input json file, use default value of None!\n",
      "/g/data/yr31/zs2131/tasks/2023/RNA_expr_net/DeepGeneNet/results/models/pretrain/exp9/model.rank0.\n",
      "checkpoint file /g/data/yr31/zs2131/tasks/2023/RNA_expr_net/DeepGeneNet/results/models/pretrain/exp9/model.rank0.epoch1.pth found.\n",
      "/g/data/yr31/zs2131/tasks/2023/RNA_expr_net/DeepGeneNet/results/models/pretrain/exp9/model.rank0.epoch1.pth\n",
      "Parameter of PERCENT_OF_MASKED_GENES_ASSIGNED_AS_TOKEN_ZERO not found in the input json file, use default value of 0.8!\n",
      "Parameter of PERCENT_OF_MASKED_GENES_ASSIGNED_AS_RANDOM_TOKENS not found in the input json file, use default value of 0.1!\n",
      "Parameter of NO_RPOJECTION not found in the input json file, use default value of False!\n",
      "Parameter of MODEL_REVERSIBLE not found in the input json file, use default value of True!\n",
      "Parameter of FEATURE_REDRAW_INTERVAL not found in the input json file, use default value of 1000!\n",
      "Parameter of OUTPUTLAYER2FCS_DROPOUT_RATE not found in the input json file, use default value of 0.1!\n",
      "Parameter of GENERALIZED_ATTENTION not found in the input json file, use default value of False!\n",
      "Parameter of EXPRESSION_EMB_TYPE not found in the input json file, use default value of positional!\n",
      "Parameter of TO_OUT_LAYER_TYPE not found in the input json file, use default value of 2FCs!\n",
      "Parameter of OUTPUT_LAYER_HIDDEN_SIZE1 not found in the input json file, use default value of 40!\n",
      "Parameter of OUTPUT_LAYER_HIDDEN_SIZE2 not found in the input json file, use default value of 20!\n",
      "Parameter of PRETRAINED_TOKEN_EMB_FOR_INIT not found in the input json file, use default value of False!\n",
      "Parameter of EPOCH_TO_HAVE_MANUAL_LR not found in the input json file, use default value of 30!\n",
      "Parameter of ONE_CYCLE_LR_PCT_START not found in the input json file, use default value of 0.2!\n",
      "Parameter of ONE_CYCLE_LR_DIV_FACTOR not found in the input json file, use default value of 5!\n",
      "Parameter of ONE_CYCLE_LR_TOTAL_STEPS not found in the input json file, use default value of 40!\n",
      "Parameter of ONE_CYCLE_LR_EPOCHS not found in the input json file, use default value of 40!\n",
      "Parameter of ADAMW_WEIGHT_DECAY not found in the input json file, use default value of 0.01!\n",
      "Reading gene_to_idx_path /g/data/yr31/zs2131/tasks/2023/RNA_expr_net/DeepGeneNet/data/embedding/coding_lncrna_gene_to_idx.json!\n",
      "Reading gene_to_idx_path /g/data/yr31/zs2131/tasks/2023/RNA_expr_net/DeepGeneNet/data/embedding/coding_lncrna_gene_to_idx.json!\n",
      "Reading gene_to_idx_path /g/data/yr31/zs2131/tasks/2023/RNA_expr_net/DeepGeneNet/data/embedding/coding_lncrna_gene_to_idx.json!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "param_json_file = \"/g/data/yr31/zs2131/tasks/2023/RNA_expr_net/DeepGeneNet/jsons/exp7_GPT_coding_lncRNA.param_config.json\"\n",
    "os.environ['PARAM_JSON_FILE'] = param_json_file\n",
    "from train.common import *\n",
    "from data.GN_Dataset import GN_Dataset\n",
    "from utils.config_loader import Config\n",
    "from utils.utils import get_device, get_model, get_config, get_gene2idx, to_numpy\n",
    "import pandas as pd\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a0398f-a0ce-4d64-b146-bcaabf66cf55",
   "metadata": {},
   "source": [
    "- **Reading Data**: Load the normalized expression matrix data file into your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcb446d4-801b-4c45-9434-8d3ee9237723",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_path = config.proj_path + \"/data/examples/ReplogleWeissman2022_K562_essential.h5ad.mean_agg.coding_lncrna.binned.tsv\"\n",
    "sample_by_gene_expr_mat = pd.read_csv(tsv_path, index_col=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c9fd896-4c2d-43aa-a7a9-0f1257dd40ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_by_gene_expr_mat_np = sample_by_gene_expr_mat.values\n",
    "gene_symbols = list(sample_by_gene_expr_mat.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7e01ea-19c2-46d1-815c-eec70bfb87f1",
   "metadata": {},
   "source": [
    "- **Preparing Dataset**: Use the provided code to prepare and format the dataset specifically for the chosen GeneRAIN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c3023cb-0a11-446d-8d00-205460d2b6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gn_dataset = GN_Dataset(sample_by_gene_expr_mat=sample_by_gene_expr_mat_np,\n",
    "                        gene_symbols = gene_symbols,\n",
    "                        num_of_genes=2048\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eb0850-09b3-46ec-a9cc-caef2ecf72aa",
   "metadata": {},
   "source": [
    "- **Example Output**: Print out a sample from the prepared dataset, allowing you to check the data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f6014cd-024c-44d2-9130-9538d6b89259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gene_indices': tensor([17592, 23756, 15556,  ..., 16902,  6913,  7281], dtype=torch.int32),\n",
       " 'masked_expression': tensor([100, 100, 100,  ...,   0,   1,  38], dtype=torch.int32),\n",
       " 'true_expression': tensor([100, 100, 100,  ...,   1,   1,   1], dtype=torch.int32),\n",
       " 'raw_expression': tensor([1999., 1998., 1998.,  ..., 1697., 1697., 1696.]),\n",
       " 'zero_expression_genes': tensor([False, False, False,  ..., False, False, False]),\n",
       " 'masked_booleans': tensor([False, False, False,  ...,  True, False,  True])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gn_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a06ae2-9785-47fb-b47d-fd4362cb44e7",
   "metadata": {},
   "source": [
    "- **Load the checkpoint, and create the model object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b7bab90-4a9d-4796-b208-901126935a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRANSFORMER_MODEL_NAME GPT\n",
      "GeneExprTransformerGPT(\n",
      "  (gene_expr_transformer): GeneExprTransformer(\n",
      "    (gpt): GPT2LMHeadModel(\n",
      "      (transformer): GPT2Model(\n",
      "        (wte): Embedding(38960, 200)\n",
      "        (wpe): Embedding(2048, 200)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (h): ModuleList(\n",
      "          (0-5): 6 x GPT2Block(\n",
      "            (ln_1): LayerNorm((200,), eps=1e-10, elementwise_affine=True)\n",
      "            (attn): GPT2Attention(\n",
      "              (c_attn): Conv1D()\n",
      "              (c_proj): Conv1D()\n",
      "              (attn_dropout): Dropout(p=0.05, inplace=False)\n",
      "              (resid_dropout): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "            (ln_2): LayerNorm((200,), eps=1e-10, elementwise_affine=True)\n",
      "            (mlp): GPT2MLP(\n",
      "              (c_fc): Conv1D()\n",
      "              (c_proj): Conv1D()\n",
      "              (act): GELUActivation()\n",
      "              (dropout): Dropout(p=0.05, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (ln_f): LayerNorm((200,), eps=1e-10, elementwise_affine=True)\n",
      "      )\n",
      "      (lm_head): Linear(in_features=200, out_features=38960, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Model checkpoint loaded from: /g/data/yr31/zs2131/tasks/2023/RNA_expr_net/DeepGeneNet//data/models/GeneRAIN.GPT_protein_coding_lncRNAs.pth\n"
     ]
    }
   ],
   "source": [
    "device = get_device()\n",
    "check_point_path = f\"{config.proj_path}/data/models/GeneRAIN.GPT_protein_coding_lncRNAs.pth\"\n",
    "model = get_model(param_json_file, check_point_path)\n",
    "model = model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c6779e2-7251-43c9-8a77-3b3e702208fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "# For testing, we only select 20 examples\n",
    "subset = torch.utils.data.Subset(gn_dataset, indices=range(20))\n",
    "dataloader = torch.utils.data.DataLoader(subset, batch_size=batch_size, shuffle=False)\n",
    "# Uncomment the code below if you want to run the whole dataset\n",
    "# dataloader = torch.utils.data.DataLoader(subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "baseline_cell_out_list = []\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        batch = {key: batch[key].to(device) for key in ['gene_indices', 'masked_expression', 'true_expression', 'raw_expression', 'zero_expression_genes', 'masked_booleans'] if key in batch}\n",
    "        \n",
    "        model_output = get_pred_using_model_and_input(model, batch['gene_indices'], batch['true_expression'], zero_expression_genes=batch['zero_expression_genes'], output_hidden_states=False)\n",
    "        # model_output = get_pred_using_model_and_input(model, batch['gene_indices'], None, output_hidden_states=False)\n",
    "        baseline_cell_out_list.append(model_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df576161",
   "metadata": {},
   "source": [
    "- **Print the loss and the shape of the logits array for each batch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88c53f56-8280-4fb1-b610-d7bf016b321d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 8.476980209350586\n",
      "logits array shape: torch.Size([2, 2048, 38960])\n",
      "loss: 8.40365982055664\n",
      "logits array shape: torch.Size([2, 2048, 38960])\n",
      "loss: 8.46461009979248\n",
      "logits array shape: torch.Size([2, 2048, 38960])\n",
      "loss: 8.388516426086426\n",
      "logits array shape: torch.Size([2, 2048, 38960])\n",
      "loss: 8.415474891662598\n",
      "logits array shape: torch.Size([2, 2048, 38960])\n",
      "loss: 8.44312858581543\n",
      "logits array shape: torch.Size([2, 2048, 38960])\n",
      "loss: 8.386070251464844\n",
      "logits array shape: torch.Size([2, 2048, 38960])\n",
      "loss: 8.439138412475586\n",
      "logits array shape: torch.Size([2, 2048, 38960])\n",
      "loss: 8.39905071258545\n",
      "logits array shape: torch.Size([2, 2048, 38960])\n",
      "loss: 8.384571075439453\n",
      "logits array shape: torch.Size([2, 2048, 38960])\n"
     ]
    }
   ],
   "source": [
    "for batch_result in baseline_cell_out_list:\n",
    "    print(f\"loss: {batch_result['loss']}\")\n",
    "    print(f\"logits array shape: {batch_result['logits'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f26aa5-524f-40f9-9ed8-1ddb7c2450a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
